{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPYs4H+6AG8KxjhfaCiccmJ"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchvision transformers pillow requests timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5T5tiITRzwK",
        "outputId": "9c48692f-9cd3-4c79-d457-64275cefaa28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.1+cu118)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (8.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.27.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.22.4)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2022.12.7)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install timm"
      ],
      "metadata": {
        "id": "2lOx62VJSTBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from io import BytesIO\n",
        "import timm\n",
        "from transformers import BertTokenizer\n",
        "\n",
        "# 1. Load and preprocess JSON data for train, test, and validation datasets\n",
        "with open(\"/content/train.json\", \"r\") as f:\n",
        "    train_data = json.load(f)\n",
        "\n",
        "with open(\"/content/test.json\", \"r\") as f:\n",
        "    test_data = json.load(f)\n",
        "\n",
        "with open(\"/content/validation.json\", \"r\") as f:\n",
        "    val_data = json.load(f)\n",
        "\n",
        "# 2. Create a custom dataset class\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, transform):\n",
        "        self.data = data\n",
        "        self.tokenizer = tokenizer\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        title = self.data[idx][\"title\"]\n",
        "        img_url = self.data[idx][\"thumbnail\"]\n",
        "        label = self.data[idx][\"Label\"]\n",
        "\n",
        "        # Tokenize title\n",
        "        tokens = self.tokenizer(title, padding=\"max_length\", truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "        # Load and preprocess image\n",
        "        try:\n",
        "            response = requests.get(img_url)\n",
        "            img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "        except (requests.exceptions.RequestException, IOError, UnidentifiedImageError):\n",
        "            img = Image.new(\"RGB\", (224, 224), color=\"black\")\n",
        "        img = self.transform(img)\n",
        "        return tokens, img, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "# 3. Create train, test, and validation datasets\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "transform = transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor()])\n",
        "train_dataset = CustomDataset(train_data, tokenizer, transform)\n",
        "test_dataset = CustomDataset(test_data, tokenizer, transform)\n",
        "val_dataset = CustomDataset(val_data, tokenizer, transform)\n",
        "\n",
        "# 4. Load a pre-trained ViT model and modify its architecture if necessary\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = timm.create_model(\"vit_base_patch16_224\", pretrained=True, num_classes=2).to(device)\n",
        "\n",
        "# 5. Train the model\n",
        "def train(model, dataloader, optimizer, criterion, device):\n",
        "    model.train()\n",
        "    for tokens, img, labels in dataloader:\n",
        "        tokens = {k: v.to(device) for k, v in tokens.items()}\n",
        "        img = img.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(img)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# 6. Evaluate the model and save the trained weights\n",
        "def evaluate(model, dataloader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    loss = 0\n",
        "    with torch.no_grad():\n",
        "        for tokens, img, labels in dataloader:\n",
        "            tokens = {k: v.to(device) for k, v in tokens.items()}\n",
        "            img = img.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(img)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            loss += criterion(outputs, labels).item()\n",
        "\n",
        "    return correct / total, loss / total\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 5\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=3e-5)\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    train(model, train_dataloader, optimizer, criterion, device)\n",
        "    train_accuracy, train_loss = evaluate(model, train_dataloader, device)\n",
        "    val_accuracy, val_loss = evaluate(model, val_dataloader, device)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}\")\n",
        "\n",
        "# Test the trained model\n",
        "test_accuracy, test_loss = evaluate(model, test_dataloader, device)\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}\")\n",
        "\n",
        "# Save the trained model weights\n",
        "torch.save(model.state_dict(), \"trained_vit_model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qt8yWGeq6W6g",
        "outputId": "666f3c41-6661-4bc8-e13c-b86e1eebacfa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Train Loss: 0.0208, Train Accuracy: 0.67, Validation Loss: 0.0233, Validation Accuracy: 0.67\n",
            "Epoch 2/5, Train Loss: 0.0200, Train Accuracy: 0.67, Validation Loss: 0.0221, Validation Accuracy: 0.67\n",
            "Epoch 3/5, Train Loss: 0.0198, Train Accuracy: 0.67, Validation Loss: 0.0219, Validation Accuracy: 0.67\n",
            "Epoch 4/5, Train Loss: 0.0205, Train Accuracy: 0.67, Validation Loss: 0.0228, Validation Accuracy: 0.67\n",
            "Epoch 5/5, Train Loss: 0.0199, Train Accuracy: 0.67, Validation Loss: 0.0221, Validation Accuracy: 0.67\n",
            "Test Accuracy: 0.64\n"
          ]
        }
      ]
    }
  ]
}